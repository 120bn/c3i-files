{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cic2018_paper_code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHTuc7wXAX7K",
        "outputId": "667159f2-c2e0-47b3-fe55-c6cad5e20310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive # to access G-Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/My Drive/C3I_NIDS\""
      ],
      "metadata": {
        "id": "kxKmI5IWG26J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/c3i/2018/proc\""
      ],
      "metadata": {
        "id": "8YLLQujVZRmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve,auc,roc_curve\n",
        "from sklearn.metrics import f1_score, make_scorer, precision_score, recall_score, matthews_corrcoef, average_precision_score, roc_auc_score, precision_recall_curve, auc, roc_curve"
      ],
      "metadata": {
        "id": "1M6qk8BKHKMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir, filename, verbose=True, train_size=50000, test_size=None, data2018=False):\n",
        "    df = pd.read_csv(f\"{data_dir}/{filename}\")\n",
        "    if data2018:\n",
        "        Y = df[\"Label\"].map(lambda x: 1 if (x == \"BENIGN\") else -1)\n",
        "        labels = df[\"Label\"]\n",
        "        df.drop(columns=[\"Label\", \"Timestamp\", \"Destination Port\"], inplace=True)\n",
        "    else:\n",
        "        Y = df[\"Label\"].map(lambda x: 1 if (x == \"Benign\") else -1)\n",
        "        labels = df[\"Label\"]\n",
        "        df.drop(columns=[\"Label\", \"Timestamp\", \"Dst Port\"], inplace=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df, Y, train_size=train_size, test_size=test_size, shuffle=True, stratify=Y, random_state=42)\n",
        "    if verbose:\n",
        "        print(\"***** Train Data *****\")\n",
        "        print(labels.loc[y_train.index].value_counts())\n",
        "        print(\"***** Test Data *****\")\n",
        "        print(labels.loc[y_test.index].value_counts())\n",
        "    return X_train, X_test, y_train, y_test, labels.loc[y_train.index], labels.loc[y_test.index]\n",
        "\n",
        "\n",
        "def load_data_fraud(data_dir, verbose=True, data2018=False):\n",
        "    df = pd.read_csv(f\"{data_dir}/all_malicious.csv\")\n",
        "    if data2018:\n",
        "        Y = df[\"Label\"].map(lambda x: 1 if (x == \"BENIGN\") else -1)\n",
        "        labels = df[\"Label\"]\n",
        "        df.drop(columns=[\"Label\", \"Timestamp\", \"Destination Port\"], inplace=True)\n",
        "    else:\n",
        "        Y = df[\"Label\"].map(lambda x: 1 if (x == \"Benign\") else -1)\n",
        "        labels = df[\"Label\"]\n",
        "        df.drop(columns=[\"Label\", \"Timestamp\", \"Dst Port\"], inplace=True)\n",
        "    if verbose:\n",
        "        print(\"***** Data *****\")\n",
        "        print(labels.value_counts())\n",
        "    return df, Y, labels"
      ],
      "metadata": {
        "id": "dx8SCA5is5UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size=50000\n",
        "test_size=500000\n",
        "epochs = 30\n",
        "validation_perc=0.15\n",
        "\n",
        "# Load benign transactions\n",
        "X_train, X_test, y_train, y_test, train_labels, test_labels = load_data(data_dir, \"benign_1M.csv\", train_size=train_size, test_size=test_size, verbose=False)\n",
        "# Load all fraud transactions\n",
        "X_fraud, y_fraud, labels_fraud = load_data_fraud(data_dir, verbose=False)\n",
        "\n",
        "\n",
        "X_test = X_test.append(X_fraud)\n",
        "y_test = y_test.append(y_fraud)\n",
        "test_labels = test_labels.append(labels_fraud)\n",
        "\n",
        "\n",
        "X_val, X_t, y_val, y_t, label_val, label_t = train_test_split(X_test, y_test, test_labels, train_size=validation_perc, random_state=42, stratify=test_labels, shuffle=True)"
      ],
      "metadata": {
        "id": "kPEENYUIxaVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCh1QV4DHZcA",
        "outputId": "2180f363-e1fa-4bdb-db63-ef3f25047ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 67)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"***** Train Data *****\")\n",
        "print(train_labels.value_counts())\n",
        "print(\"***** Validation Data *****\")\n",
        "print(label_val.value_counts())\n",
        "print(\"***** Test Data *****\")\n",
        "print(label_t.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCjGhx3e2wkd",
        "outputId": "6134a410-bd81-419d-b680-a129bb4bd131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Train Data *****\n",
            "Benign    50000\n",
            "Name: Label, dtype: int64\n",
            "***** Validation Data *****\n",
            "Benign                      75000\n",
            "DDOS attack-HOIC            29829\n",
            "DoS attacks-Hulk            21780\n",
            "Bot                         21680\n",
            "Infilteration               19468\n",
            "SSH-Bruteforce              14106\n",
            "DoS attacks-GoldenEye        6211\n",
            "DoS attacks-Slowloris        1486\n",
            "DDOS attack-LOIC-UDP          260\n",
            "Brute Force -Web               83\n",
            "Brute Force -XSS               34\n",
            "SQL Injection                  12\n",
            "FTP-BruteForce                  8\n",
            "DoS attacks-SlowHTTPTest        6\n",
            "Name: Label, dtype: int64\n",
            "***** Test Data *****\n",
            "Benign                      425000\n",
            "DDOS attack-HOIC            169032\n",
            "DoS attacks-Hulk            123419\n",
            "Bot                         122855\n",
            "Infilteration               110318\n",
            "SSH-Bruteforce               79935\n",
            "DoS attacks-GoldenEye        35195\n",
            "DoS attacks-Slowloris         8422\n",
            "DDOS attack-LOIC-UDP          1470\n",
            "Brute Force -Web               471\n",
            "Brute Force -XSS               194\n",
            "SQL Injection                   67\n",
            "FTP-BruteForce                  45\n",
            "DoS attacks-SlowHTTPTest        37\n",
            "Name: Label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def anomaly_scores(original, transformed):\n",
        "    sse = np.sum((original - transformed)**2, axis=1)\n",
        "    return sse\n",
        "\n",
        "def evaluate_results(y_true, score):\n",
        "    precision, recall, threshold = precision_recall_curve(y_true, score, pos_label=-1)\n",
        "    au_precision_recall = auc(recall, precision)\n",
        "    results = pd.DataFrame({'precision': precision, 'recall': recall})\n",
        "    results[\"f1\"] = 2*precision*recall/(precision+recall)\n",
        "    max_index = results[\"f1\"].idxmax()\n",
        "    best = results.loc[results[\"f1\"].idxmax()]\n",
        "    best[\"threshold\"] = threshold[max_index]\n",
        "    best[\"au_precision_recall\"] = au_precision_recall\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, score, pos_label=-1)\n",
        "    best[\"auroc\"] = auc(fpr, tpr)\n",
        "    return best\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred):\n",
        "    results = {}\n",
        "    results['recall'] = recall_score(y_true, y_pred, pos_label=-1, zero_division=0)\n",
        "    results['precision'] = precision_score(y_true, y_pred, pos_label=-1, zero_division=0)\n",
        "    results['f1'] = f1_score(y_true, y_pred, pos_label=-1, zero_division=0)\n",
        "    return results\n",
        "\n",
        "def evaluate_test_data(y_true, score, threshold):\n",
        "    y_pred = np.array([1 if score < threshold else -1 for score in score])\n",
        "    results = evaluate_predictions(y_true, y_pred)\n",
        "    precision, recall, threshold = precision_recall_curve(y_true, score, pos_label=-1)\n",
        "    results['au_precision_recall'] = auc(recall, precision)\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, score, pos_label=-1)\n",
        "    results[\"auroc\"] = auc(fpr, tpr)\n",
        "    return results"
      ],
      "metadata": {
        "id": "DlBCj0-SDO6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = QuantileTransformer(output_distribution='normal')\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_val_s = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "3wMJCO8x4Lnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=32, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(X_train_s)\n",
        "x_train_feature = pca.transform(X_train_s)\n",
        "x_val_feature = pca.transform(X_val_s)\n",
        "#X_val_pca = pca.transform(X_val_s)\n",
        "X_val_pca_inv = pca.inverse_transform(x_val_feature)\n",
        "val_score_pca = anomaly_scores(X_val_s, X_val_pca_inv)\n",
        "val_metrics_pca = evaluate_results(y_val, val_score_pca)\n"
      ],
      "metadata": {
        "id": "0vcM-t2UE9n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics_pca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jWBQ_vVIzrQ",
        "outputId": "390bb96f-4e20-49d8-871b-770b01eb1c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "precision              0.773014\n",
              "recall                 0.874238\n",
              "f1                     0.820516\n",
              "threshold              0.251872\n",
              "au_precision_recall    0.791557\n",
              "auroc                  0.770298\n",
              "Name: 57527, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolation Forest        \n",
        "forest = IsolationForest(bootstrap=False, contamination=4.161677249308696e-05, max_features=0.6674219692639616, max_samples=0.8646939376341813, random_state=42, verbose=0, warm_start=False)\n",
        "        \n",
        "forest.fit(x_train_feature)\n",
        "y_val_pred = forest.predict(x_val_feature)\n",
        "val_metrics_if = evaluate_predictions(y_val, y_val_pred)\n",
        "y_val_score = forest.decision_function(x_val_feature)\n",
        "val_metrics_if = evaluate_results(y_val, -y_val_score)"
      ],
      "metadata": {
        "id": "3HWadTq_JKa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics_if"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8fWyCyKOQuH",
        "outputId": "3706c7ad-e00e-4b51-f82b-e08a413dad20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "precision              0.805743\n",
              "recall                 0.905596\n",
              "f1                     0.852756\n",
              "threshold             -0.319912\n",
              "au_precision_recall    0.809632\n",
              "auroc                  0.810264\n",
              "Name: 42428, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "pca = PCA(n_components=32, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "\n",
        "pca = PCA(n_components=32, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(X_train_s)\n",
        "x_train_feature = pca.transform(X_train_s)\n",
        "x_val_feature = pca.transform(X_val_s)\n",
        "\n",
        "svm = OneClassSVM(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, nu=0.5, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
        "svm.fit(x_train_feature)\n",
        "y_val_pred = svm.predict(x_val_feature)\n",
        "val_metrics = evaluate_predictions(y_val, y_val_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "UifXgH0waigU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPbxp_lJecZo",
        "outputId": "dfea639c-6d07-41f9-85c8-ecf6e7cc2dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.5133642524477633,\n",
              " 'precision': 0.581903344905494,\n",
              " 'recall': 0.45926950410131956}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_score = svm.decision_function(x_val_feature)\n",
        "\n",
        "evaluate_results(y_val, -y_val_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbsVUs1Oe4n3",
        "outputId": "c156360e-d4d0-434e-a602-24432e780f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "precision                0.620985\n",
              "recall                   0.992702\n",
              "f1                       0.764031\n",
              "threshold             -550.215984\n",
              "au_precision_recall      0.545456\n",
              "auroc                    0.400312\n",
              "Name: 6182, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.regularizers import l2\n",
        "from keras.losses import mean_squared_error\n",
        "\n"
      ],
      "metadata": {
        "id": "4xQKHwgzbxhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}