{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc17b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 174000\r\n",
      "drwxr-xr-x 2 root root      4096 Jun 14 14:09 1\r\n",
      "-rw-r--r-- 1 root root 178170641 Jun 20 05:53 conn.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7a70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "ll = []\n",
    "def read_zeek_files(filename):\n",
    "    file_time = {}\n",
    "    cache_lines = {}\n",
    "    lines = 0\n",
    "    if not filename.endswith('.log'):\n",
    "        filename += '.log'\n",
    "    filename_without_ext = filename.split('/')[-1].split('.')[0]\n",
    "    file_handler = open(filename, 'r')\n",
    "#     pbar = tqdm(total = 60000000)\n",
    "    while True:\n",
    "#         tqdm.monitor()\n",
    "        zeek_line = file_handler.readline()\n",
    "        if not zeek_line:\n",
    "            return\n",
    "        try:\n",
    "            nline = json.loads(zeek_line)\n",
    "            line = {'type': filename, 'data': nline}\n",
    "            timestamp = nline.get('ts', 0)\n",
    "#             print(\"json works\")\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            nline = zeek_line\n",
    "            if not nline or nline[0] == '#':\n",
    "                print(\"nline comment or over\")\n",
    "                continue\n",
    "            line = {'type': filename, 'data': nline}\n",
    "            timestamp = nline.split('\\t')[0]\n",
    "            print(\"json decode error\")\n",
    "        try:\n",
    "            file_time[filename] = float(timestamp)\n",
    "            cache_lines[filename] = line\n",
    "        except ValueError:\n",
    "            pass\n",
    "        files_sorted_by_ts = sorted(file_time, key=file_time.get)\n",
    "        try:\n",
    "            file_with_earliest_flow = files_sorted_by_ts[0]\n",
    "        except IndexError:\n",
    "            print(\"index error\")\n",
    "        line_to_send = cache_lines[file_with_earliest_flow]\n",
    "#         print('\t> Sent Line: {}'.format(line_to_send), 0, 3)\n",
    "#         ll.append(line_to_send)\n",
    "        del cache_lines[file_with_earliest_flow]\n",
    "        del file_time[file_with_earliest_flow]\n",
    "        lines += 1\n",
    "        yield line_to_send\n",
    "#         pbar.update(1)\n",
    "#     file_handler.close()\n",
    "#     return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67774c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "ll = []\n",
    "def read_zeek_files2(filename):\n",
    "    file_time = {}\n",
    "    cache_lines = {}\n",
    "    lines = 0\n",
    "    if not filename.endswith('.log'):\n",
    "        filename += '.log'\n",
    "    filename_without_ext = filename.split('/')[-1].split('.')[0]\n",
    "    file_handler = open(filename, 'r')\n",
    "    pbar = tqdm(total = 6000)\n",
    "    while lines < 6000:\n",
    "#         tqdm.monitor()\n",
    "        zeek_line = file_handler.readline()\n",
    "        if not zeek_line:\n",
    "            return\n",
    "        try:\n",
    "            nline = json.loads(zeek_line)\n",
    "            line = {'type': filename, 'data': nline}\n",
    "            timestamp = nline.get('ts', 0)\n",
    "#             print(\"json works\")\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            nline = zeek_line\n",
    "            if not nline or nline[0] == '#':\n",
    "                print(\"nline comment or over\")\n",
    "                continue\n",
    "            line = {'type': filename, 'data': nline}\n",
    "            timestamp = nline.split('\\t')[0]\n",
    "            print(\"json decode error\")\n",
    "        try:\n",
    "            file_time[filename] = float(timestamp)\n",
    "            cache_lines[filename] = line\n",
    "        except ValueError:\n",
    "            pass\n",
    "        files_sorted_by_ts = sorted(file_time, key=file_time.get)\n",
    "        try:\n",
    "            file_with_earliest_flow = files_sorted_by_ts[0]\n",
    "        except IndexError:\n",
    "            print(\"index error\")\n",
    "        line_to_send = cache_lines[file_with_earliest_flow]\n",
    "#         print('\t> Sent Line: {}'.format(line_to_send), 0, 3)\n",
    "        ll.append(line_to_send)\n",
    "        del cache_lines[file_with_earliest_flow]\n",
    "        del file_time[file_with_earliest_flow]\n",
    "        lines += 1\n",
    "#         yield line_to_send\n",
    "        pbar.update(1)\n",
    "    file_handler.close()\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384c10f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'dataset/1/conn.log', 'data': {'ts': 1331901000.0, 'uid': 'CUySP6353GMmKYJETb', 'id.orig_h': '192.168.202.79', 'id.orig_p': 46117, 'id.resp_h': '192.168.229.254', 'id.resp_p': 443, 'proto': 'tcp', 'conn_state': 'SF', 'missed_bytes': 0, 'history': '^dDafFr', 'orig_pkts': 3, 'orig_ip_bytes': 382, 'resp_pkts': 9, 'resp_ip_bytes': 994, 'vlan': 120, 'orig_l2_addr': '00:0c:29:41:4b:e7', 'resp_l2_addr': '00:16:47:9d:f2:c2', 'emoji': ''}}\n",
      "{'type': 'dataset/1/conn.log', 'data': {'ts': 1331901000.0, 'uid': 'CctNbQQy6OKXKEHmg', 'id.orig_h': '192.168.202.79', 'id.orig_p': 50463, 'id.resp_h': '192.168.229.251', 'id.resp_p': 80, 'proto': 'tcp', 'conn_state': 'SH', 'missed_bytes': 0, 'history': 'Fa', 'orig_pkts': 1, 'orig_ip_bytes': 52, 'resp_pkts': 1, 'resp_ip_bytes': 52, 'vlan': 120, 'orig_l2_addr': '00:0c:29:41:4b:e7', 'resp_l2_addr': '00:16:47:9d:f2:c2', 'emoji': ''}}\n",
      "{'type': 'dataset/1/conn.log', 'data': {'ts': 1331901000.0, 'uid': 'C4CRnB4oVj0mx9Vsjg', 'id.orig_h': '192.168.202.79', 'id.orig_p': 50465, 'id.resp_h': '192.168.229.251', 'id.resp_p': 80, 'proto': 'tcp', 'service': 'http', 'duration': 0.009999990463256836, 'orig_bytes': 166, 'resp_bytes': 214, 'conn_state': 'SF', 'missed_bytes': 0, 'history': 'ShADfFa', 'orig_pkts': 4, 'orig_ip_bytes': 382, 'resp_pkts': 3, 'resp_ip_bytes': 382, 'vlan': 120, 'orig_l2_addr': '00:0c:29:41:4b:e7', 'resp_l2_addr': '00:16:47:9d:f2:c2', 'emoji': '🏄'}}\n",
      "{'type': 'dataset/1/conn.log', 'data': {'ts': 1331901000.01, 'uid': 'CvEzGe1ZcHyuitvAM3', 'id.orig_h': '192.168.202.79', 'id.orig_p': 50467, 'id.resp_h': '192.168.229.251', 'id.resp_p': 80, 'proto': 'tcp', 'service': 'http', 'duration': 0.009999990463256836, 'orig_bytes': 166, 'resp_bytes': 214, 'conn_state': 'SF', 'missed_bytes': 0, 'history': 'ShADfFa', 'orig_pkts': 4, 'orig_ip_bytes': 382, 'resp_pkts': 3, 'resp_ip_bytes': 382, 'vlan': 120, 'orig_l2_addr': '00:0c:29:41:4b:e7', 'resp_l2_addr': '00:16:47:9d:f2:c2', 'emoji': '🏄'}}\n",
      "{'type': 'dataset/1/conn.log', 'data': {'ts': 1331901000.0, 'uid': 'Ct4qR51i2Po08qkWhc', 'id.orig_h': '192.168.202.79', 'id.orig_p': 46119, 'id.resp_h': '192.168.229.254', 'id.resp_p': 443, 'proto': 'tcp', 'service': 'ssl', 'duration': 0.019999980926513672, 'orig_bytes': 544, 'resp_bytes': 1060, 'conn_state': 'SF', 'missed_bytes': 0, 'history': 'ShADadfFr', 'orig_pkts': 8, 'orig_ip_bytes': 968, 'resp_pkts': 13, 'resp_ip_bytes': 1744, 'vlan': 120, 'orig_l2_addr': '00:0c:29:41:4b:e7', 'resp_l2_addr': '00:16:47:9d:f2:c2', 'emoji': '🚨🥵'}}\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in read_zeek_files(\"dataset/1/conn.log\"):\n",
    "    print(i)\n",
    "    j+=1\n",
    "    if (j == 5):\n",
    "        break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e43623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_zeek_files2(\"dataset/1/conn.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb65741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe232cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ll[0:10]:\n",
    "#     print(i[\"data\"][\"uid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d022dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from StratosphereLinuxIPS.slips_files.common.slips_utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a94411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import __database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118ec3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 6379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5bba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__database__.connect_to_redis_server(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0ab32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tzlocal import get_localzone\n",
    "local_timezone = get_localzone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c7af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "\n",
    "def get_time(time: str) -> datetime:\n",
    "    timeformat=None\n",
    "    \"\"\"\n",
    "    Take time in string and return datetime object.\n",
    "    The format of time can be completely different. It can be seconds, or dates with specific formats.\n",
    "    If user does not define the time format in configuration file, we have to try most frequent cases of time formats.\n",
    "    :param time: epoch time\n",
    "    \"\"\"\n",
    "    \n",
    "    if not timeformat:\n",
    "        # The time format was not defined from configuration file neither from last flows.\n",
    "        timeformat = utils.define_time_format(time)\n",
    "    if not timeformat:\n",
    "        # We did not find the right time format.\n",
    "        outputqueue.put(\n",
    "            '01|profiler|[Profile] We did not find right time format. Please set the time format in the configuration file.'\n",
    "        )\n",
    "    defined_datetime: datetime = None\n",
    "    if timeformat:\n",
    "        if timeformat == 'unixtimestamp':\n",
    "            # The format of time is in epoch unix timestamp.\n",
    "            # Correct datetime according to the current timezone\n",
    "            defined_datetime = datetime.fromtimestamp(\n",
    "                float(time), local_timezone\n",
    "            )\n",
    "        else:\n",
    "            try:\n",
    "                # The format of time is a complete date.\n",
    "                # Dont modify it, since\n",
    "                # 1) The time is a string, so we dont know the original timezone\n",
    "                # 2) the python call datetime.fromtimestamp uses by default\n",
    "                # the local zone when nothing is specified.\n",
    "                # https://docs.python.org/3/library/datetime.html#datetime.timezone\n",
    "                # convert epoch to datetime obj and use the current timezone\n",
    "                # self.print(time)\n",
    "                # self.print(self.local_timezone)\n",
    "                # defined_datetime = datetime.strptime(time, self.timeformat)#.astimezone(self.local_timezone)\n",
    "                # defined_datetime = datetime.fromtimestamp(float(time), self.local_timezone)\n",
    "                # defined_datetime = datetime.fromtimestamp(float(time), self.local_timezone)\n",
    "                # convert dt obj to user specified tiemformat\n",
    "                # defined_datetime = defined_datetime.strftime(self.timeformat)\n",
    "                defined_datetime = time\n",
    "            except ValueError:\n",
    "                defined_datetime = None\n",
    "    else:\n",
    "        # We do not know the time format so we can not read it.\n",
    "        outputqueue.put(\n",
    "            '01|profiler|[Profile] We did not find right time format. Please set the time format in the configuration file.'\n",
    "        )\n",
    "\n",
    "    # if defined_datetime is None and self.timeformat:\n",
    "    # There is suricata issue with invalid timestamp for examaple: \"1900-01-00T00:00:08.511802+0000\"\n",
    "    # pass\n",
    "    return defined_datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be02cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_line(new_line):\n",
    "    column_values = {}\n",
    "    line = new_line['data']\n",
    "    file_type = new_line['type']\n",
    "    # all zeek lines recieved from stdin should be of type conn\n",
    "    if file_type == 'stdin' and new_line.get('line_type', False) == 'zeek':\n",
    "        file_type = 'conn'\n",
    "    else:\n",
    "        # if the zeek dir given to slips has 'conn' in it's name,\n",
    "        # slips thinks it's reading a conn file\n",
    "        # because we use the file path as the file 'type'\n",
    "        # to fix this, only use the file name as file 'type'\n",
    "        file_type = file_type.split('/')[-1]\n",
    "    \n",
    "    column_values['type'] = ''\n",
    "    ts = line.get('ts', False)\n",
    "    if ts:\n",
    "        column_values['starttime'] = get_time(ts)\n",
    "    else:\n",
    "        column_values['starttime'] = ''\n",
    "\n",
    "    column_values['uid'] = line.get('uid', False)\n",
    "    column_values['saddr'] = line.get('id.orig_h', '')\n",
    "    column_values['daddr'] = line.get('id.resp_h', '')\n",
    "    \n",
    "    if 'conn' in file_type:\n",
    "            # {'ts': 1538080852.403669, 'uid': 'Cewh6D2USNVtfcLxZe', 'id.orig_h': '192.168.2.12', 'id.orig_p': 56343,\n",
    "            # 'id.resp_h': '192.168.2.1', 'id.resp_p': 53, 'proto': 'udp', 'service': 'dns', 'duration': 0.008364,\n",
    "            # 'orig_bytes': 30, 'resp_bytes': 94, 'conn_state': 'SF', 'missed_bytes': 0, 'history': 'Dd', 'orig_pkts': 1,\n",
    "            # 'orig_ip_bytes': 58, 'resp_pkts': 1, 'resp_ip_bytes': 122, 'orig_l2_addr': 'b8:27:eb:6a:47:b8',\n",
    "            # 'resp_l2_addr': 'a6:d1:8c:1f:ce:64', 'type': './zeek_files/conn'}\n",
    "\n",
    "            column_values.update(\n",
    "                {\n",
    "                    'type': 'conn',\n",
    "                    'dur': float(line.get('duration', 0)),\n",
    "                    'endtime': str(column_values['starttime'])\n",
    "                    + str(timedelta(seconds=float(line.get('duration', 0)))),\n",
    "                    'proto': line['proto'],\n",
    "                    'appproto': line.get('service', ''),\n",
    "                    'sport': line.get('id.orig_p', ''),\n",
    "                    'dport': line.get('id.resp_p', ''),\n",
    "                    'state': line.get('conn_state', ''),\n",
    "                    'dir': '->',\n",
    "                    'spkts': line.get('orig_pkts', 0),\n",
    "                    'dpkts': line.get('resp_pkts', 0),\n",
    "                    'sbytes': line.get('orig_bytes', 0),\n",
    "                    'dbytes': line.get('resp_bytes', 0),\n",
    "                    'pkts': line.get('orig_bytes', 0)\n",
    "                    + line.get('resp_pkts', 0),\n",
    "                    'bytes': line.get('orig_bytes', 0)\n",
    "                    + line.get('resp_bytes', 0),\n",
    "                    'state_hist': line.get(\n",
    "                        'history', line.get('conn_state', '')\n",
    "                    ),\n",
    "                    'smac': line.get('orig_l2_addr', ''),\n",
    "                    'dmac': line.get('resp_l2_addr', ''),\n",
    "                }\n",
    "            )\n",
    "    elif 'dns' in file_type:\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'dns',\n",
    "                'query': line.get('query', ''),\n",
    "                'qclass_name': line.get('qclass_name', ''),\n",
    "                'qtype_name': line.get('qtype_name', ''),\n",
    "                'rcode_name': line.get('rcode_name', ''),\n",
    "                'answers': line.get('answers', ''),\n",
    "                'TTLs': line.get('TTLs', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if type(column_values['answers']) == str:\n",
    "            # If the answer is only 1, Zeek gives a string\n",
    "            # so convert to a list\n",
    "            column_values.update(\n",
    "                {'answers': [column_values['answers']]}\n",
    "            )\n",
    "\n",
    "    elif 'http' in file_type:\n",
    "        # {\"ts\":158.957403,\"uid\":\"CnNLbE2dyfy5KyqEhh\",\"id.orig_h\":\"10.0.2.105\",\"id.orig_p\":49158,\"id.resp_h\":\"64.182.208.181\",\"id.resp_p\":80,\"trans_depth\":1,\"method\":\"GET\",\"host\":\"icanhazip.com\",\"uri\":\"/\",\"version\":\"1.1\",\"user_agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.38 (KHTML, like Gecko) Chrome/45.0.2456.99 Safari/537.38\",\"request_body_len\":0,\"response_body_len\":13,\"status_code\":200,\"status_msg\":\"OK\",\"tags\":[],\"resp_fuids\":[\"FwraVxIOACcjkaGi3\"],\"resp_mime_types\":[\"text/plain\"]}\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'http',\n",
    "                'method': line.get('method', ''),\n",
    "                'host': line.get('host', ''),\n",
    "                'uri': line.get('uri', ''),\n",
    "                'httpversion': line.get('version', 0),\n",
    "                'user_agent': line.get('user_agent', ''),\n",
    "                'request_body_len': line.get('request_body_len', 0),\n",
    "                'response_body_len': line.get('response_body_len', 0),\n",
    "                'status_code': line.get('status_code', ''),\n",
    "                'status_msg': line.get('status_msg', ''),\n",
    "                'resp_mime_types': line.get('resp_mime_types', ''),\n",
    "                'resp_fuids': line.get('resp_fuids', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif 'ssl' in file_type:\n",
    "        # {\"ts\":12087.045499,\"uid\":\"CdoFDp4iW79I5ZmsT7\",\"id.orig_h\":\"10.0.2.105\",\"id.orig_p\":49704,\"id.resp_h\":\"195.211.240.166\",\"id.resp_p\":443,\"version\":\"SSLv3\",\"cipher\":\"TLS_RSA_WITH_RC4_128_SHA\",\"resumed\":false,\"established\":true,\"cert_chain_fuids\":[\"FhGp1L3yZXuURiPqq7\"],\"client_cert_chain_fuids\":[],\"subject\":\"OU=DAHUATECH,O=DAHUA,L=HANGZHOU,ST=ZHEJIANG,C=CN,CN=192.168.1.108\",\"issuer\":\"O=DahuaTech,L=HangZhou,ST=ZheJiang,C=CN,CN=Product Root CA\",\"validation_status\":\"unable to get local issuer certificate\"}\n",
    "        # {\"ts\":1382354909.915615,\"uid\":\"C7W6ZA4vI8FxJ9J0bh\",\"id.orig_h\":\"147.32.83.53\",\"id.orig_p\":36567,\"id.resp_h\":\"195.113.214.241\",\"id.resp_p\":443,\"version\":\"TLSv12\",\"cipher\":\"TLS_ECDHE_ECDSA_WITH_RC4_128_SHA\",\"curve\":\"secp256r1\",\"server_name\":\"id.google.com.ar\",\"resumed\":false,\"established\":true,\"cert_chain_fuids\":[\"FnomJz1vghKIOHtytf\",\"FSvQff1KsaDkRtKXo4\",\"Fif2PF48bytqq6xMDb\"],\"client_cert_chain_fuids\":[],\"subject\":\"CN=*.google.com,O=Google Inc,L=Mountain View,ST=California,C=US\",\"issuer\":\"CN=Google Internet Authority G2,O=Google Inc,C=US\",\"validation_status\":\"ok\"}\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'ssl',\n",
    "                'sslversion': line.get('version', ''),\n",
    "                'sport': line.get('id.orig_p', ','),\n",
    "                'dport': line.get('id.resp_p', ','),\n",
    "                'cipher': line.get('cipher', ''),\n",
    "                'resumed': line.get('resumed', ''),\n",
    "                'established': line.get('established', ''),\n",
    "                'cert_chain_fuids': line.get('cert_chain_fuids', ''),\n",
    "                'client_cert_chain_fuids': line.get(\n",
    "                    'client_cert_chain_fuids', ''\n",
    "                ),\n",
    "                'subject': line.get('subject', ''),\n",
    "                'issuer': line.get('issuer', ''),\n",
    "                'validation_status': line.get('validation_status', ''),\n",
    "                'curve': line.get('curve', ''),\n",
    "                'server_name': line.get('server_name', ''),\n",
    "                'ja3': line.get('ja3', ''),\n",
    "                'is_DoH': line.get('is_DoH', 'false'),\n",
    "                'ja3s': line.get('ja3s', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif 'ssh' in file_type:\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'ssh',\n",
    "                'version': line.get('version', ''),\n",
    "                'auth_success': line.get('auth_success', ''),\n",
    "                'auth_attempts': line.get('auth_attempts', ''),\n",
    "                'client': line.get('client', ''),\n",
    "                'server': line.get('server', ''),\n",
    "                'cipher_alg': line.get('cipher_alg', ''),\n",
    "                'mac_alg': line.get('mac_alg', ''),\n",
    "                'compression_alg': line.get('compression_alg', ''),\n",
    "                'kex_alg': line.get('kex_alg', ''),\n",
    "                'host_key_alg': line.get('host_key_alg', ''),\n",
    "                'host_key': line.get('host_key', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif 'irc' in file_type:\n",
    "        column_values.update({'type': 'irc'})\n",
    "    elif 'long' in file_type:\n",
    "        column_values.update({'type': 'long'})\n",
    "    elif 'dhcp' in file_type:\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'dhcp',\n",
    "                'client_addr': line.get('client_addr', ''),\n",
    "                'server_addr': line.get('server_addr', ''),\n",
    "                'host_name': line.get('host_name', ''),\n",
    "                'mac': line.get('mac', ''),  # this is the client mac\n",
    "                'saddr': line.get('client_addr', ''),\n",
    "                'daddr': line.get('server_addr', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # self.column_values['domain'] = line.get('domain','')\n",
    "        # self.column_values['assigned_addr'] = line.get('assigned_addr','')\n",
    "\n",
    "        # Some zeek flow don't have saddr or daddr, seen in dhcp.log and notice.log use the mac address instead\n",
    "        if (\n",
    "            column_values['saddr'] == ''\n",
    "            and column_values['daddr'] == ''\n",
    "            and line.get('mac', False)\n",
    "        ):\n",
    "            column_values.update({'saddr': line.get('mac', '')})\n",
    "\n",
    "    elif 'dce_rpc' in file_type:\n",
    "        column_values.update({'type': 'dce_rpc'})\n",
    "    elif 'dnp3' in file_type:\n",
    "        column_values.update({'type': 'dnp3'})\n",
    "    elif 'ftp' in file_type:\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'ftp',\n",
    "                'used_port': line.get('data_channel.resp_p', False),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif 'kerberos' in file_type:\n",
    "        column_values.update({'type': 'kerberos'})\n",
    "    elif 'mysql' in file_type:\n",
    "        column_values.update({'type': 'mysql'})\n",
    "    elif 'modbus' in file_type:\n",
    "        column_values.update({'type': 'modbus'})\n",
    "    elif 'ntlm' in file_type:\n",
    "        column_values.update({'type': 'ntlm'})\n",
    "    elif 'rdp' in file_type:\n",
    "        column_values.update({'type': 'rdp'})\n",
    "    elif 'sip' in file_type:\n",
    "        column_values.update({'type': 'sip'})\n",
    "    elif 'smb_cmd' in file_type:\n",
    "        column_values.update({'type': 'smb_cmd'})\n",
    "    elif 'smb_files' in file_type:\n",
    "        column_values.update({'type': 'smb_files'})\n",
    "    elif 'smb_mapping' in file_type:\n",
    "        column_values.update({'type': 'smb_mapping'})\n",
    "    elif 'smtp' in file_type:\n",
    "        column_values.update(\n",
    "            {'type': 'smtp', 'last_reply': line.get('last_reply', '')}\n",
    "        )\n",
    "    elif 'socks' in file_type:\n",
    "        column_values.update({'type': 'socks'})\n",
    "    elif 'syslog' in file_type:\n",
    "        column_values.update({'type': 'syslog'})\n",
    "    elif 'tunnel' in file_type:\n",
    "        column_values.update({'type': 'tunnel'})\n",
    "    elif 'notice' in file_type:\n",
    "        \"\"\"Parse the fields we're interested in in the notice.log file\"\"\"\n",
    "        # notice fields: ts - uid id.orig_h(saddr) - id.orig_p(sport) - id.resp_h(daddr) - id.resp_p(dport) - note - msg\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'notice',\n",
    "                'sport': line.get('id.orig_p', ''),\n",
    "                'dport': line.get('id.resp_p', ''),\n",
    "                # self.column_values['scanned_ip'] = line.get('dst', '')\n",
    "                'note': line.get('note', ''),\n",
    "                'msg': line.get(\n",
    "                    'msg', ''\n",
    "                ),  # we,'re looking for self signed certs in this field\n",
    "                'scanned_port': line.get('p', ''),\n",
    "                'scanning_ip': line.get('src', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # portscan notices don't have id.orig_h or id.resp_h fields, instead they have src and dst\n",
    "        if column_values['saddr'] == '':\n",
    "            column_values.update({'saddr': line.get('src', '')})\n",
    "        if column_values['daddr'] == '':\n",
    "            # set daddr to src for now because the notice that contains portscan doesn't have a dst field and slips needs it to work\n",
    "            column_values.update(\n",
    "                {'daddr': line.get('dst', column_values['saddr'])}\n",
    "            )\n",
    "\n",
    "    elif 'files.log' in file_type:\n",
    "        \"\"\"Parse the fields we're interested in in the files.log file\"\"\"\n",
    "        # the slash before files to distinguish between 'files' in the dir name and file.log\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'files',\n",
    "                'uid': line.get('conn_uids', [''])[0],\n",
    "                'saddr': line.get('tx_hosts', [''])[0],\n",
    "                'daddr': line.get('rx_hosts', [''])[0],\n",
    "                'size': line.get('seen_bytes', ''),  # downloaded file size\n",
    "                'md5': line.get('md5', ''),\n",
    "                # used for detecting ssl certs\n",
    "                'source': line.get('source', ''),\n",
    "                'analyzers': line.get('analyzers', ''),\n",
    "                'sha1': line.get('sha1', ''),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif 'arp' in file_type:\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'arp',\n",
    "                'src_mac': line.get('src_mac', ''),\n",
    "                'dst_mac': line.get('dst_mac', ''),\n",
    "                'saddr': line.get('orig_h', ''),\n",
    "                'daddr': line.get('resp_h', ''),\n",
    "                'dst_hw': line.get('resp_hw', ''),\n",
    "                'src_hw': line.get('orig_hw', ''),\n",
    "                'operation': line.get('operation', ''),\n",
    "            }\n",
    "        )\n",
    "    elif 'known_services' in file_type:\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'known_services',\n",
    "                'saddr': line.get('host', ''),\n",
    "                # this file doesn't have a daddr field, but we need it in add_flow_to_profile\n",
    "                'daddr': '0.0.0.0',\n",
    "                'port_num': line.get('port_num', ''),\n",
    "                'port_proto': line.get('port_proto', ''),\n",
    "                'service': line.get('service', ''),\n",
    "            }\n",
    "        )\n",
    "    elif 'software' in file_type:\n",
    "        software_type = line.get('software_type', '')\n",
    "        # store info about everything except http:broswer\n",
    "        # we're already reading browser UA from http.log\n",
    "        if software_type == 'HTTP::BROWSER':\n",
    "            return column_values\n",
    "        column_values.update(\n",
    "            {\n",
    "                'type': 'software',\n",
    "                'saddr': line.get('host', ''),\n",
    "                'software_type': software_type,\n",
    "                'unparsed_version': line.get('unparsed_version', ''),\n",
    "                'version.major': line.get('version.major', ''),\n",
    "                'version.minor': line.get('version.minor', ''),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return False\n",
    "    return column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b773f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import configparser\n",
    "# from .database import __database__\n",
    "from StratosphereLinuxIPS.slips_files.common.slips_utils import utils\n",
    "import ipaddress\n",
    "import traceback\n",
    "import requests\n",
    "import os\n",
    "import binascii\n",
    "import base64\n",
    "import validators\n",
    "from re import split\n",
    "from tzlocal import get_localzone\n",
    "# from .whitelist import Whitelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f35694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af87c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_line(ll[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5a0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd8fd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54635da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh = []\n",
    "# for i in tqdm(ll):\n",
    "#     l = process_line(i)\n",
    "#     if l:\n",
    "#         hh.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a4a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f58215c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_symbol(\n",
    "    profileid,\n",
    "    twid,\n",
    "    tupleid,\n",
    "    current_time,\n",
    "    current_duration,\n",
    "    current_size,\n",
    "    tuple_key: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function computes the new symbol for the tuple according to the\n",
    "    original stratosphere ips model of letters\n",
    "    Here we do not apply any detection model, we just create the letters\n",
    "    as one more feature current_time is the starttime of the flow\n",
    "    \"\"\"\n",
    "    try:\n",
    "        current_duration = float(current_duration)\n",
    "        current_size = int(current_size)\n",
    "        now_ts = float(current_time)\n",
    "#         print(\n",
    "#             'Starting compute symbol. Profileid: {}, Tupleid {}, time:{} ({}), dur:{}, size:{}'.format(\n",
    "#                 profileid,\n",
    "#                 tupleid,\n",
    "#                 current_time,\n",
    "#                 type(current_time),\n",
    "#                 current_duration,\n",
    "#                 current_size,\n",
    "#             ),\n",
    "#             3,\n",
    "#             0,\n",
    "#         )\n",
    "        # Variables for computing the symbol of each tuple\n",
    "        T2 = False\n",
    "        TD = False\n",
    "        # Thresholds learnt from Stratosphere ips first version\n",
    "        # Timeout time, after 1hs\n",
    "        tto = timedelta(seconds=3600)\n",
    "        tt1 = float(1.05)\n",
    "        tt2 = float(1.3)\n",
    "        tt3 = float(5)\n",
    "        td1 = float(0.1)\n",
    "        td2 = float(10)\n",
    "        ts1 = float(250)\n",
    "        ts2 = float(1100)\n",
    "\n",
    "        # Get the time of the last flow in this tuple, and the last last\n",
    "        # Implicitely this is converting what we stored as 'now' into 'last_ts' and what we stored as 'last_ts' as 'last_last_ts'\n",
    "        (last_last_ts, last_ts) = __database__.getT2ForProfileTW(\n",
    "            profileid, twid, tupleid, tuple_key\n",
    "        )\n",
    "        # print(f'Profileid: {profileid}. Data extracted from DB. last_ts: {last_ts}, last_last_ts: {last_last_ts}', 0, 5)\n",
    "\n",
    "        def compute_periodicity(\n",
    "            now_ts: float, last_ts: float, last_last_ts: float\n",
    "        ):\n",
    "            \"\"\"Function to compute the periodicity\"\"\"\n",
    "            zeros = ''\n",
    "            if last_last_ts is False or last_ts is False:\n",
    "                TD = -1\n",
    "                T1 = None\n",
    "                T2 = None\n",
    "            else:\n",
    "                # Time diff between the past flow and the past-past flow.\n",
    "                T1 = last_ts - last_last_ts\n",
    "                # Time diff between the current flow and the past flow.\n",
    "                # We already computed this before, but we can do it here again just in case\n",
    "                T2 = now_ts - last_ts\n",
    "\n",
    "                # We have a time out of 1hs. After that, put 1 number 0 for each hs\n",
    "                # It should not happen that we also check T1... right?\n",
    "                if T2 >= tto.total_seconds():\n",
    "                    t2_in_hours = T2 / tto.total_seconds()\n",
    "                    # Shoud round it. Because we need the time to pass to really count it\n",
    "                    # For example:\n",
    "                    # 7100 / 3600 =~ 1.972  ->  int(1.972) = 1\n",
    "                    for i in range(int(t2_in_hours)):\n",
    "                        # Add the zeros to the symbol object\n",
    "                        zeros += '0'\n",
    "\n",
    "                # Compute TD\n",
    "                try:\n",
    "                    if T2 >= T1:\n",
    "                        TD = T2 / T1\n",
    "                    else:\n",
    "                        TD = T1 / T2\n",
    "                except ZeroDivisionError:\n",
    "                    TD = 1\n",
    "\n",
    "                # Decide the periodic based on TD and the thresholds\n",
    "                if TD <= tt1:\n",
    "                    # Strongly periodicity\n",
    "                    TD = 1\n",
    "                elif TD <= tt2:\n",
    "                    # Weakly periodicity\n",
    "                    TD = 2\n",
    "                elif TD <= tt3:\n",
    "                    # Weakly not periodicity\n",
    "                    TD = 3\n",
    "                elif TD > tt3:\n",
    "                    # Strongly not periodicity\n",
    "                    TD = 4\n",
    "#             print(\n",
    "#                 'Compute Periodicity: Profileid: {}, Tuple: {}, T1={}, T2={}, TD={}'.format(\n",
    "#                     profileid, tupleid, T1, T2, TD\n",
    "#                 ),\n",
    "#                 3,\n",
    "#                 0,\n",
    "#             )\n",
    "            return TD, zeros\n",
    "\n",
    "        def compute_duration():\n",
    "            \"\"\"Function to compute letter of the duration\"\"\"\n",
    "            if current_duration <= td1:\n",
    "                return 1\n",
    "            elif current_duration > td1 and current_duration <= td2:\n",
    "                return 2\n",
    "            elif current_duration > td2:\n",
    "                return 3\n",
    "\n",
    "        def compute_size():\n",
    "            \"\"\"Function to compute letter of the size\"\"\"\n",
    "            if current_size <= ts1:\n",
    "                return 1\n",
    "            elif current_size > ts1 and current_size <= ts2:\n",
    "                return 2\n",
    "            elif current_size > ts2:\n",
    "                return 3\n",
    "\n",
    "        def compute_letter():\n",
    "            \"\"\"Function to compute letter\"\"\"\n",
    "            # format of this map is as follows\n",
    "            # {periodicity: {'size' : {duration: letter, duration: letter, etc.}}\n",
    "            periodicity_map = {\n",
    "                # every key in this dict represents a periodicity\n",
    "                '-1': {\n",
    "                    # every key in this dict is a size 1,2,3\n",
    "                    # 'size' : {duration: letter, diration: letter, etc.}\n",
    "                    '1': {'1': '1', '2': '2', '3': '3'},\n",
    "                    '2': {'1': '4', '2': '5', '3': '6'},\n",
    "                    '3': {'1': '7', '2': '8', '3': '9'},\n",
    "                },\n",
    "                '1': {\n",
    "                    '1': {'1': 'a', '2': 'b', '3': 'c'},\n",
    "                    '2': {'1': 'd', '2': 'e', '3': 'f'},\n",
    "                    '3': {'1': 'g', '2': 'h', '3': 'i'},\n",
    "                },\n",
    "                '2': {\n",
    "                    '1': {'1': 'A', '2': 'B', '3': 'C'},\n",
    "                    '2': {'1': 'D', '2': 'E', '3': 'F'},\n",
    "                    '3': {'1': 'G', '2': 'H', '3': 'I'},\n",
    "                },\n",
    "                '3': {\n",
    "                    '1': {'1': 'r', '2': 's', '3': 't'},\n",
    "                    '2': {'1': 'u', '2': 'v', '3': 'w'},\n",
    "                    '3': {'1': 'x', '2': 'y', '3': 'z'},\n",
    "                },\n",
    "                '4': {\n",
    "                    '1': {'1': 'R', '2': 'S', '3': 'T'},\n",
    "                    '2': {'1': 'U', '2': 'V', '3': 'W'},\n",
    "                    '3': {'1': 'X', '2': 'Y', '3': 'Z'},\n",
    "                },\n",
    "            }\n",
    "            return periodicity_map[str(periodicity)][str(size)][\n",
    "                str(duration)\n",
    "            ]\n",
    "\n",
    "        def compute_timechar():\n",
    "            \"\"\"Function to compute the timechar\"\"\"\n",
    "            # print(f'Compute timechar. Profileid: {profileid} T2: {T2}', 0, 5)\n",
    "            if not isinstance(T2, bool):\n",
    "                if T2 <= timedelta(seconds=5).total_seconds():\n",
    "                    return '.'\n",
    "                elif T2 <= timedelta(seconds=60).total_seconds():\n",
    "                    return ','\n",
    "                elif T2 <= timedelta(seconds=300).total_seconds():\n",
    "                    return '+'\n",
    "                elif T2 <= timedelta(seconds=3600).total_seconds():\n",
    "                    return '*'\n",
    "                else:\n",
    "                    # Changed from 0 to ''\n",
    "                    return ''\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        # Here begins the function's code\n",
    "        try:\n",
    "            # Update value of T2\n",
    "            if now_ts and last_ts:\n",
    "                T2 = now_ts - last_ts\n",
    "            else:\n",
    "                T2 = False\n",
    "            # Are flows sorted?\n",
    "            if T2 < 0:\n",
    "                # Flows are not sorted!\n",
    "                # What is going on here when the flows are not ordered?? Are we losing flows?\n",
    "                # Put a warning\n",
    "                print(\n",
    "                    'Warning: Coming flows are not sorted -> Some time diff are less than zero.',\n",
    "                    0,\n",
    "                    2,\n",
    "                )\n",
    "                pass\n",
    "        except TypeError:\n",
    "            T2 = False\n",
    "        # print(\"T2:{}\".format(T2), 0, 1)\n",
    "        # p = __database__.start_profiling()\n",
    "        # Compute the rest\n",
    "        periodicity, zeros = compute_periodicity(\n",
    "            now_ts, last_ts, last_last_ts\n",
    "        )\n",
    "        duration = compute_duration()\n",
    "        # print(\"Duration: {}\".format(duration), 0, 1)\n",
    "        size = compute_size()\n",
    "        # print(\"Size: {}\".format(size), 0, 1)\n",
    "        letter = compute_letter()\n",
    "        # print(\"Letter: {}\".format(letter), 0, 1)\n",
    "        timechar = compute_timechar()\n",
    "        # print(\"TimeChar: {}\".format(timechar), 0, 1)\n",
    "#         print(\n",
    "#             'Profileid: {}, Tuple: {}, Periodicity: {}, Duration: {}, Size: {}, Letter: {}. TimeChar: {}'.format(\n",
    "#                 profileid,\n",
    "#                 tupleid,\n",
    "#                 periodicity,\n",
    "#                 duration,\n",
    "#                 size,\n",
    "#                 letter,\n",
    "#                 timechar,\n",
    "#             ),\n",
    "#             3,\n",
    "#             0,\n",
    "#         )\n",
    "        # p = __database__.end_profiling(p)\n",
    "        symbol = zeros + letter + timechar\n",
    "        # Return the symbol, the current time of the flow and the T1 value\n",
    "        return symbol, (last_ts, now_ts)\n",
    "    except Exception as inst:\n",
    "        # For some reason we can not use the output queue here.. check\n",
    "        print('Error in compute_symbol in profilerProcess.', 0, 1)\n",
    "        print('{}'.format(type(inst)), 0, 1)\n",
    "        print('{}'.format(inst), 0, 1)\n",
    "        print('{}'.format(traceback.format_exc()), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9975351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh[3402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba3393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_values = hh[3402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30a6778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_separator = __database__.getFieldSeparator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd44d63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95282b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_values['uid'] = base64.b64encode(\n",
    "#                     binascii.b2a_hex(os.urandom(9))\n",
    "#                 ).decode('utf-8')\n",
    "# uid = column_values['uid']\n",
    "# flow_type = column_values['type']\n",
    "# saddr = column_values['saddr']\n",
    "# daddr = column_values['daddr']\n",
    "# profileid = 'profile' + id_separator + str(saddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f97a3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timewindow(flowtime, profileid):\n",
    "    \"\"\" \"\n",
    "    This function should get the id of the TW in the database where the flow belong.\n",
    "    If the TW is not there, we create as many tw as necessary in the future or past until we get the correct TW for this flow.\n",
    "    - We use this function to avoid retrieving all the data from the DB for the complete profile. We use a separate table for the TW per profile.\n",
    "    -- Returns the time window id\n",
    "    THIS IS NOT WORKING:\n",
    "    - The empty profiles in the middle are not being created!!!\n",
    "    - The Dtp ips are stored in the first time win\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First check if we are not in the last TW. Since this will be the majority of cases\n",
    "\n",
    "        try:\n",
    "            if not profileid:\n",
    "                # profileid is None if we're dealing with a profile\n",
    "                # outside of home_network when this param is given\n",
    "                return False\n",
    "            [\n",
    "                (lasttwid, lasttw_start_time)\n",
    "            ] = __database__.getLastTWforProfile(profileid)\n",
    "            lasttw_start_time = float(lasttw_start_time)\n",
    "            lasttw_end_time = lasttw_start_time + width\n",
    "            flowtime = float(flowtime)\n",
    "#             print(\n",
    "#                 'The last TW id for profile {} was {}. Start:{}. End: {}'.format(\n",
    "#                     profileid, lasttwid, lasttw_start_time, lasttw_end_time\n",
    "#                 ),\n",
    "#                 3,\n",
    "#                 0,\n",
    "#             )\n",
    "            # There was a last TW, so check if the current flow belongs here.\n",
    "            if (\n",
    "                lasttw_end_time > flowtime\n",
    "                and lasttw_start_time <= flowtime\n",
    "            ):\n",
    "#                 print(\n",
    "#                     'The flow ({}) is on the last time window ({})'.format(\n",
    "#                         flowtime, lasttw_end_time\n",
    "#                     ),\n",
    "#                     3,\n",
    "#                     0,\n",
    "#                 )\n",
    "                twid = lasttwid\n",
    "            elif lasttw_end_time <= flowtime:\n",
    "                # The flow was not in the last TW, its NEWER than it\n",
    "#                 print(\n",
    "#                     'The flow ({}) is NOT on the last time window ({}). Its newer'.format(\n",
    "#                         flowtime, lasttw_end_time\n",
    "#                     ),\n",
    "#                     3,\n",
    "#                     0,\n",
    "#                 )\n",
    "                amount_of_new_tw = int(\n",
    "                    (flowtime - lasttw_end_time) / width\n",
    "                )\n",
    "#                 print(\n",
    "#                     'We have to create {} empty TWs in the midle.'.format(\n",
    "#                         amount_of_new_tw\n",
    "#                     ),\n",
    "#                     3,\n",
    "#                     0,\n",
    "#                 )\n",
    "                temp_end = lasttw_end_time\n",
    "                for id in range(0, amount_of_new_tw + 1):\n",
    "                    new_start = temp_end\n",
    "                    twid = __database__.addNewTW(profileid, new_start)\n",
    "#                     print(\n",
    "#                         'Creating the TW id {}. Start: {}.'.format(\n",
    "#                             twid, new_start\n",
    "#                         ),\n",
    "#                         3,\n",
    "#                         0,\n",
    "#                     )\n",
    "                    temp_end = new_start + width\n",
    "                # Now get the id of the last TW so we can return it\n",
    "            elif lasttw_start_time > flowtime:\n",
    "                # The flow was not in the last TW, its OLDER that it\n",
    "#                 print(\n",
    "#                     'The flow ({}) is NOT on the last time window ({}). Its older'.format(\n",
    "#                         flowtime, lasttw_end_time\n",
    "#                     ),\n",
    "#                     3,\n",
    "#                     0,\n",
    "#                 )\n",
    "                # Find out if we already have this TW in the past\n",
    "                data = __database__.getTWofTime(profileid, flowtime)\n",
    "                if data:\n",
    "                    # We found a TW where this flow belongs to\n",
    "                    (twid, tw_start_time) = data\n",
    "                    return twid\n",
    "                else:\n",
    "                    # There was no TW that included the time of this flow, so create them in the past\n",
    "                    # How many new TW we need in the past?\n",
    "                    # amount_of_new_tw is the total amount of tw we should have under the new situation\n",
    "                    amount_of_new_tw = int(\n",
    "                        (lasttw_end_time - flowtime) / width\n",
    "                    )\n",
    "                    # amount_of_current_tw is the real amount of tw we have now\n",
    "                    amount_of_current_tw = (\n",
    "                        __database__.getamountTWsfromProfile(profileid)\n",
    "                    )\n",
    "                    # diff is the new ones we should add in the past. (Yes, we could have computed this differently)\n",
    "                    diff = amount_of_new_tw - amount_of_current_tw\n",
    "#                     print(\n",
    "#                         'We need to create {} TW before the first'.format(\n",
    "#                             diff + 1\n",
    "#                         ),\n",
    "#                         3,\n",
    "#                         0,\n",
    "#                     )\n",
    "                    # Get the first TW\n",
    "                    [\n",
    "                        (firsttwid, firsttw_start_time)\n",
    "                    ] = __database__.getFirstTWforProfile(profileid)\n",
    "                    firsttw_start_time = float(firsttw_start_time)\n",
    "                    # The start of the new older TW should be the first - the width\n",
    "                    temp_start = firsttw_start_time - width\n",
    "                    for id in range(0, diff + 1):\n",
    "                        new_start = temp_start\n",
    "                        # The method to add an older TW is the same as to add a new one, just the starttime changes\n",
    "                        twid = __database__.addNewOlderTW(\n",
    "                            profileid, new_start\n",
    "                        )\n",
    "#                         print(\n",
    "#                             'Creating the new older TW id {}. Start: {}.'.format(\n",
    "#                                 twid, new_start\n",
    "#                             ),\n",
    "#                             3,\n",
    "#                             0,\n",
    "#                         )\n",
    "                        temp_start = new_start - width\n",
    "        except ValueError:\n",
    "            # There is no last tw. So create the first TW\n",
    "            # If the option for only-one-tw was selected, we should create the TW at least 100 years before the flowtime, to cover for\n",
    "            # 'flows in the past'. Which means we should cover for any flow that is coming later with time before the first flow\n",
    "            if width == 9999999999:\n",
    "                # Seconds in 1 year = 31536000\n",
    "                startoftw = float(flowtime - (31536000 * 100))\n",
    "            else:\n",
    "                startoftw = float(flowtime)\n",
    "            # Add this TW, of this profile, to the DB\n",
    "            twid = __database__.addNewTW(profileid, startoftw)\n",
    "            # print(\"First TW ({}) created for profile {}.\".format(twid, profileid), 0, 1)\n",
    "        return twid\n",
    "    except Exception as e:\n",
    "        print('Error in get_timewindow().', 0, 1)\n",
    "        print('{}'.format(e), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1294fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = column_values['starttime']\n",
    "# if type(ts) == str:\n",
    "#     datetime_obj = datetime.strptime(ts, timeformat)\n",
    "#     starttime = datetime_obj.timestamp()\n",
    "# else:\n",
    "#     starttime = column_values['starttime'].timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41cbd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dur = column_values['dur']\n",
    "# sport = column_values['sport']\n",
    "# dport = column_values['dport']\n",
    "# sport = column_values['sport']\n",
    "# proto = column_values['proto']\n",
    "# state = column_values['state']\n",
    "# pkts = column_values['pkts']\n",
    "# allbytes = column_values['bytes']\n",
    "# spkts = column_values['spkts']\n",
    "# sbytes = column_values['sbytes']\n",
    "# endtime = column_values['endtime']\n",
    "# appproto = column_values['appproto']\n",
    "# direction = column_values['dir']\n",
    "# dpkts = column_values['dpkts']\n",
    "# dbytes = column_values['dbytes']\n",
    "# smac = column_values.get('smac')\n",
    "# dmac = column_values.get('dmac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a276534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "# saddr = column_values['saddr']\n",
    "# daddr = column_values['daddr']\n",
    "# try:\n",
    "#     saddr_as_obj = ipaddress.IPv4Address(saddr)\n",
    "#     daddr_as_obj = ipaddress.IPv4Address(daddr)\n",
    "#     # Is ipv4\n",
    "# except ipaddress.AddressValueError:\n",
    "#     # Is it ipv6?\n",
    "#     try:\n",
    "#         saddr_as_obj = ipaddress.IPv6Address(saddr)\n",
    "#         daddr_as_obj = ipaddress.IPv6Address(daddr)\n",
    "#     except ipaddress.AddressValueError:\n",
    "#         # Its a mac\n",
    "#         print(12)\n",
    "# tupleid = f'{daddr_as_obj}-{dport}-{proto}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1fd06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "conf = configparser.ConfigParser(interpolation=None)\n",
    "f = open(\"./StratosphereLinuxIPS/slips.conf\", \"r\")\n",
    "conf.read_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6c0eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = conf.get('parameters', 'time_window_width')\n",
    "    width = float(data)\n",
    "except ValueError:\n",
    "    # Its not a float\n",
    "    if 'only_one_tw' in data:\n",
    "        # Only one tw. Width is 10 9s, wich is ~11,500 days, ~311 years\n",
    "        width = 9999999999\n",
    "except configparser.NoOptionError:\n",
    "    # By default we use 3600 seconds, 1hs\n",
    "    width = 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08d4f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "__database__.start(config=conf, redis_port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0533018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue\n",
    "outputqueue = Queue()\n",
    "inputqueue = Queue()\n",
    "__database__.setOutputQueue(outputqueue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a6cae90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# twid = get_timewindow(starttime, profileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "448453e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52e5c843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460887\r"
     ]
    }
   ],
   "source": [
    "uid_list = []\n",
    "symbols_list = []\n",
    "llll = 0\n",
    "for i in read_zeek_files(\"dataset/conn.log\"):\n",
    "    llll+=1\n",
    "    print(llll, end='\\r')\n",
    "    column_values = i\n",
    "    uid_list.append(i[\"data\"][\"uid\"])\n",
    "    column_values = process_line(column_values)\n",
    "    column_values['uid'] = base64.b64encode(\n",
    "                    binascii.b2a_hex(os.urandom(9))\n",
    "                ).decode('utf-8')\n",
    "    uid = column_values['uid']\n",
    "    flow_type = column_values['type']\n",
    "    saddr = column_values['saddr']\n",
    "    daddr = column_values['daddr']\n",
    "    profileid = 'profile' + id_separator + str(saddr)\n",
    "    ts = column_values['starttime']\n",
    "    if type(ts) == str:\n",
    "        datetime_obj = datetime.strptime(ts, timeformat)\n",
    "        starttime = datetime_obj.timestamp()\n",
    "    else:\n",
    "        starttime = column_values['starttime'].timestamp()\n",
    "    dur = column_values['dur']\n",
    "    sport = column_values['sport']\n",
    "    dport = column_values['dport']\n",
    "    sport = column_values['sport']\n",
    "    proto = column_values['proto']\n",
    "    state = column_values['state']\n",
    "    pkts = column_values['pkts']\n",
    "    allbytes = column_values['bytes']\n",
    "    spkts = column_values['spkts']\n",
    "    sbytes = column_values['sbytes']\n",
    "    endtime = column_values['endtime']\n",
    "    appproto = column_values['appproto']\n",
    "    direction = column_values['dir']\n",
    "    dpkts = column_values['dpkts']\n",
    "    dbytes = column_values['dbytes']\n",
    "    smac = column_values.get('smac')\n",
    "    dmac = column_values.get('dmac')\n",
    "    saddr = column_values['saddr']\n",
    "    daddr = column_values['daddr']\n",
    "    try:\n",
    "        saddr_as_obj = ipaddress.IPv4Address(saddr)\n",
    "        daddr_as_obj = ipaddress.IPv4Address(daddr)\n",
    "        # Is ipv4\n",
    "    except ipaddress.AddressValueError:\n",
    "        # Is it ipv6?\n",
    "        try:\n",
    "            saddr_as_obj = ipaddress.IPv6Address(saddr)\n",
    "            daddr_as_obj = ipaddress.IPv6Address(daddr)\n",
    "        except ipaddress.AddressValueError:\n",
    "            # Its a mac\n",
    "            print(12)\n",
    "    tupleid = f'{daddr_as_obj}-{dport}-{proto}'\n",
    "    twid = get_timewindow(starttime, profileid)\n",
    "#     print(\"profileid = \",profileid)\n",
    "    symbol = compute_symbol(\n",
    "                        profileid,\n",
    "                        twid,\n",
    "                        tupleid,\n",
    "                        starttime,\n",
    "                        dur,\n",
    "                        allbytes,\n",
    "                        tuple_key='OutTuples',\n",
    "                    )\n",
    "#     print(type(symbol))\n",
    "    symbols_list.append(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc033aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('uid.pickle', 'wb') as handle:\n",
    "#     pickle.dump(uid_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# import pickle\n",
    "# with open('symbol.pickle', 'wb') as handle:\n",
    "#     pickle.dump(symbols_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ec6abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f31d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ffa4e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uid_list) == len(set(uid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "964a21bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460887"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "655f9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = []\n",
    "for i in symbols_list:\n",
    "    aaa.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eee0ab0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460887"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f41bc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profileid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2727d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3154be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compute symbol. Profileid: profile_192.168.202.79, Tupleid 192.168.229.153-49160-tcp, time:1331901115.37 (<class 'float'>), dur:0.06000018119812012, size:322 3 0\n",
      "Compute Periodicity: Profileid: profile_192.168.202.79, Tuple: 192.168.229.153-49160-tcp, T1=None, T2=None, TD=-1 3 0\n",
      "Profileid: profile_192.168.202.79, Tuple: 192.168.229.153-49160-tcp, Periodicity: -1, Duration: 1, Size: 2, Letter: 4. TimeChar:  3 0\n"
     ]
    }
   ],
   "source": [
    "symbol = compute_symbol(\n",
    "                        profileid,\n",
    "                        twid,\n",
    "                        tupleid,\n",
    "                        starttime,\n",
    "                        dur,\n",
    "                        allbytes,\n",
    "                        tuple_key='OutTuples',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "314204d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4', (False, 1331901115.37))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afdfa817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '2', '3', '4', '5', '6', '7', '8', '9'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d63a828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '7',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '7',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '7',\n",
       " '7',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '7',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b29b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------here----\n"
     ]
    }
   ],
   "source": [
    "# from StratosphereLinuxIPS.slips_files.core.profilerProcess import ProfilerProcess\n",
    "# from StratosphereLinuxIPS.slips_files.core.inputProcess import InputProcess\n",
    "\n",
    "# procs = ProfilerProcess(inputqueue, outputqueue,debug=True, config=conf,redis_port=6379, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e48763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# procs.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5b2e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137721"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# procs.pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a3c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profilerProcessQueue = Queue()\n",
    "\n",
    "# input_information = \"~/dataset/1/dns.log\"\n",
    "# input_type = 'stdin'\n",
    "# line_type = 'zeek'\n",
    "# redis_port=6379\n",
    "# pcapfilter=None\n",
    "# zeek_bro='zeek'\n",
    "\n",
    "# inputProcess = InputProcess(\n",
    "#                 outputqueue,\n",
    "#                 profilerProcessQueue,\n",
    "#                 input_type,\n",
    "#                 input_information,\n",
    "#                 conf,\n",
    "#                 pcapfilter,\n",
    "#                 zeek_bro,\n",
    "#                 line_type,\n",
    "#                 redis_port,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bfe39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputProcess.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76e0dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __database__.getProfilesLen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc2b878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d63182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# port = 6379\n",
    "# r = redis.StrictRedis(\n",
    "#                 host='localhost',\n",
    "#                 port=port,\n",
    "#                 db=0,\n",
    "#                 charset='utf-8',\n",
    "#                 socket_keepalive=True,\n",
    "#                 retry_on_timeout=True,\n",
    "#                 decode_responses=True,\n",
    "#                 health_check_interval=20,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb230b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_separator = __database__.getFieldSeparator()\n",
    "# profileid = 'profile' + id_separator + str(saddr)\n",
    "# separator = '_'\n",
    "# hash_id = profileid + separator + twid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93403fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.hget()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
